{
    "messages": [
        {
            "role": "system", 
            "content": "Goal:\nPrioritize the student's expertise and abilities, while ensuring the school record is highly readable and easy to understand, taking into account the content of the inputted school record.\n\nSystem Role Content:\n\t1. Emphasis on Expertise and Abilities (Written in Korean):\n\t\t- Considering the content of the inputted school record, emphasize the student's academic achievements and personal development as central to their expertise and abilities.\n\t\t- Highlight creative thinking, problem-solving skills, mathematical logic, and scientific analytical abilities with concrete examples.\n\t\t- Showcase cooperative attitude and leadership through activity examples.\n\t\t- Simplify complex content with examples or analogies while maintaining expertise by using key technical terms.\n\t2. Emphasis on Leadership and Teamwork:\n\t\t- Detail leadership and teamwork abilities in school activities, clubs, sports teams, and volunteer work.\n\t\t- Describe problem-solving instances through cooperation and communication in challenging situations.\n\t3. Emphasis on Contribution to School and Community:\n\t\t- Detail contributions through volunteer activities and project participation in schools and communities.\n\t\t- Emphasize active participation and leadership shown in initiatives, campaigns, and event planning for the community.\n\t4. Personalized Content (Written in Korean):\n\t\t- Professionally express the student's experiences and achievements in an easily understandable language.\n\t\t- Concisely write personalized content without losing professionalism."
        }, 
        {
            "role": "user", 
            "content": "교내 독서의 밤 행사에서 책 '세계미래보고서 2023'와 인공지능 주제로 토론과 부스운영을 진행함. 인공지능과 관련된 일자리 문제, 개발 제한 문제, 윤리 문제 등의 주제로 토론을 진행하였고, 토론을 진행하기 전 참여자들의 배경지식을 생성하기 위해 computer vision 개발을 후배들과 함께 진행하여 데이터 수집, 전처리, 모델 구축, 모델 학습, 결과 예측의 과정을 경험하여 인공지능을 개발해 볼 수 있는 기회를 제공함. 여러 탐구를 진행하며 구글, 도서, 논문 등 다양한 검색엔진을 이용하면서 기존 키워드 기반 검색엔진(TF-IDF)이 쿼리 속 키워드의 존재에 따라 추천하여 문맥과 다의어를 고려하지 못하여 사용자가 원하지 않는 자료까지 추천하는 한계를 발견함. 이를 NLP AI를 통해 문서의 내용을 수치화 할 수 있다면 문제를 해결할 수 있다고 생각하여 KoBERT를 활용한 ‘SBERT의 문장 임베딩 기반 검색엔진 개발 연구’를 진행함.공간 벡터에서 각 차원 수치 중 가장 큰 값만 추출하는 Max Pooling층을 BERT모델 위에 얹어 은닉층을 통해 의미 벡터를 만들어내는 Bi-Encoder 형태로 KoBERT를 KoSBERT로 파인튜닝함. 이 모델에 약 2500개의 네이버 기사 크롤링 데이터를 텍스트 정제, 불용어 처리, 정규화 등의 전처리를 진행하고 770차원의 공간벡터에 임베딩을 진행함, 이를 밀도 기반 클러스터링으로 군집을 나누고 그 군집마다 유사한 내용을 가지고 있는지를 비교하여 임베딩 성능을 확인함. 이렇게 개발된 키워드 기반 알고리즘과 단어 쿼리 결과와 문장 쿼리 정확도를 비교함. 단일 쿼리의 경우 임베딩 기반 검색엔진이 비교적 낮은 성능을, 문장 쿼리에서는 비교적 높은 성능을 보였으며, 이 차이를 독립표본 t 검정을 진행하여 단일 쿼리 결과에서는 유의수준을 0.05보다 높아 귀무가설을, 문장 쿼리에서는 유의수준보다 낮아 대립가설을 체택하여 모델의 성능을 비교분석함. 추후 이 모델을 '정기발행물 재가공 시스템 연구 프로젝트'로 확장하여, 독서 교과에서 정기발행물의 정보 노후화 문제를 해결하기 위한 프로젝트를 진행함. 위 ‘정기발행물 재가공 시스템 연구 프로젝트’에서 GPT의 문서요약을 사용하는데 이는 지연 시간과 api 비용 때문에 상용화에 어려움이 있음을 발견하였고, 한정된 task에서 GPT와 유사한 성능을 가진 모델을 GPT 결과값을 이용해 제작하는 방법에 관심을 갖기 시작함. 이에 대한 첫 모델로 Attention Mechanism을 이용한 텍스트 요약 알고리즘을 개발함. seq2seq 모델의 인코더와 디코더 모두 LSTM층 4개로 구성하고, 이 모델의 인코더와 디코더 n번째 히든레이어끼리 내적을 통해 n번째 토큰에 대한 어텐션 가중치를 만들어 이 값에 따라 디코더로 요약텍스트를 출력할 수 있도록 Attention Mechanism을 적용함. 학습데이터로는 5개의 분야의 약 7000개의 기사와 GPT를 통해 요약한 요약문을 데이터로 사용하였고, 그 결과 문서 요약의 소요시간은 GPT보다 10초 빠르지만, GPT와 유사한 정확도를 만들어내는 모델을 만들어냄."
        }, 
        {
            "role": "assistant", 
            "content": "교내 독서의 밤 행사에서 책 '세계미래보고서 2023'와 인공지능 주제 참가자들의 배경 지식의 확장을 위해computer vision 개발 과정에 따른 데이터 워크 플로우 작성 과정을 공유하는 등 유연하고 개방적 사고로 학생들을 이끄는 리더쉽을 갖춘 학생임. 기존 키워드 기반 검색엔진(TF-IDF)이  문맥과 다의어를 고려하지 못하여 사용자가 원하지 않는 자료까지 추천하는 한계를 발견함. 이에 자료내 가중치 적용한 문장을 수치화해, 해당 문제를 해결하고자  주제 연구 킥오프에서 KoBERT를 활용한 ‘SBERT의 문장 임베딩 기반 검색엔진 개발 활동을  진행함. 공간 벡터에서 각 차원 수치 중 가장 큰 값만 추출하는 Max Pooling층을 BERT모델 위에 얹어 은닉층을 통해 의미 벡터를 만들어내는 Bi-Encoder 형태로 KoBERT를 KoSBERT로 파인튜닝함. 네이버 기사 크롤링 데이터를 텍스트 정제, 불용어 처리, 정규화 등의 전처리를 진행해, 770차원의 공간벡터에 임베딩함, 이를 밀도 기반 클러스터링으로 군집화해 유사성과 상이성을을 비교해 임베딩 성능을 확인함. 분석 결과, 임베딩 기반 검색엔진이  단일 쿼리보다 문장 쿼리에서 상대적으로 높은 성능을 보임.  쿼리 종류별 성능 검증을 위해  독립표본 t 검정에서 유의수준 0.05로 설정해  문장 쿼리에서 유의수준보다 낮아 대립가설이 성립함을 선보이는 등 현상에 대한 문제 인식과 분석, 뛰어난 과제 집착력이 남다른 학생임. 이를 토대로,  정기발행물 재가공 시스템 연구 프로젝트에서 정기발행물의 정보 노후화 문제를 해결하기 위한 프로젝트로 발전시킴. 특히 GPT 문서요약 과정에서 지연 시간과 api 비용의 한계점을 들어,한정된 재화내에서 유사 성능을 보이는 Attention Mechanism을 이용한 텍스트 요약 알고리즘 개발을 진행함.. seq2seq 모델의 인코더와 디코더 모두 LSTM층 4개로 구성하고, 이 모델의 인코더와 디코더 은닉층에서 내적 및 재귀적 함수 성질을 활용해 각 토큰에 대한 어텐션 가중치를  요약텍스트를 출력하도록 함. 7000개의 기사 자료를 토대로 실제 GPT 3.5 터보와의 성능 비교에서 더 빠른 속도와 정확도를 보임을 확인하는 등 창의적 아이디어와 논리력, 지치지 않는 과제 집착력이 타의 추종을 불허함. 할 수 있도록 Attention Mechanism을 적용함. 학습데이터로는 5개의 분야의 약 7000개의 기사와 GPT를 통해 요약한 요약문을 데이터로 사용하였고, 그 결과 문서 요약의 소요시간은 GPT보다 10초 빠른 모델을 제작함."
        }
    ]
}


